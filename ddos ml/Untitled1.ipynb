{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'jaccard_similarity_score' from 'sklearn.metrics' (C:\\Users\\Pruthvi S\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d69bf81696c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#from xgboost import XGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#import xgboost as xgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjaccard_similarity_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'jaccard_similarity_score' from 'sklearn.metrics' (C:\\Users\\Pruthvi S\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Nov  8 23:08:54 2019\n",
    "\n",
    "@author: RAhul\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.ensemble import xgbclassifier\n",
    "#from xgboost import XGBClassifier\n",
    "#import xgboost as xgb\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "df = pd.read_csv('cybersecurity_training.csv', sep='|', index_col=False)\n",
    "\n",
    "#print(df.info())\n",
    "\n",
    "#df.to_excel('C:\\\\Users\\\\lenova\\\\Desktop\\\\coursera material\\\\Rahul asst\\\\knowledge_pit\\\\cybersecurity_training\\\\sample.xlsx')\n",
    "list(df.columns)\n",
    "missing_data = df.isnull()\n",
    "\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")  \n",
    "#----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "feature = df[[\n",
    " 'categoryname',\n",
    " 'ipcategory_name',\n",
    " 'ipcategory_scope',\n",
    " 'parent_category',\n",
    " 'grandparent_category',\n",
    " 'overallseverity',\n",
    " 'weekday',\n",
    " 'correlatedcount',\n",
    " 'n1',\n",
    " 'n2',\n",
    " 'n3',\n",
    " 'n4',\n",
    " 'n5',\n",
    " 'n6',\n",
    " 'n7',\n",
    " 'n8',\n",
    " 'n9',\n",
    " 'n10',\n",
    " 'score',\n",
    " 'srcip_cd',\n",
    " 'dstip_cd',\n",
    " 'srcport_cd',\n",
    " 'dstport_cd',\n",
    " 'alerttype_cd',\n",
    " 'direction_cd',\n",
    " 'eventname_cd',\n",
    " 'severity_cd',\n",
    " 'reportingdevice_cd',\n",
    " 'devicetype_cd',\n",
    " 'devicevendor_cd',\n",
    " 'domain_cd',\n",
    " 'protocol_cd',\n",
    " 'username_cd',\n",
    " 'srcipcategory_cd',\n",
    " 'dstipcategory_cd',\n",
    " 'isiptrusted',\n",
    " 'untrustscore',\n",
    " 'flowscore',\n",
    " 'trustscore',\n",
    " 'enforcementscore',\n",
    " 'dstipcategory_dominate',\n",
    " 'srcipcategory_dominate',\n",
    " 'dstportcategory_dominate',\n",
    " 'srcportcategory_dominate',\n",
    " 'thrcnt_month',\n",
    " 'thrcnt_week',\n",
    " 'thrcnt_day',\n",
    " 'p6',\n",
    " 'p9',\n",
    " 'p5m',\n",
    " 'p5w',\n",
    " 'p5d',\n",
    " 'p8m',\n",
    " 'p8w',\n",
    " 'p8d']]\n",
    "\n",
    "#----------------------------------------Filling missing values--------------------------------------------------------\n",
    "\n",
    "#mode_feature = feature[[ 'n1',\n",
    "# 'n2',\n",
    "# 'n3',\n",
    "# 'n4',\n",
    "# 'n5',\n",
    "# 'n6',\n",
    "# 'n7',\n",
    "# 'n8',\n",
    "# 'n9',\n",
    "# 'n10',\n",
    "# 'score']].astype(\"float\").mode(axis=0)\n",
    "\n",
    "feature.replace(\"\", np.nan, inplace = True)\n",
    "\n",
    "feature['score'].value_counts()\n",
    "\n",
    "feature['score'].fillna(1, inplace = True)\n",
    "\n",
    "feature.fillna(0, inplace = True)\n",
    "\n",
    "#feature[[ 'n1',\n",
    "# 'n2',\n",
    "# 'n3',\n",
    "# 'n4',\n",
    "# 'n5',\n",
    "# 'n6',\n",
    "# 'n7',\n",
    "# 'n8',\n",
    "# 'n9',\n",
    "# 'n10',\n",
    "# 'score']].replace(np.nan, mode_feature, inplace=True)\n",
    "\n",
    "\n",
    "#-----------------Onehot Encoding-----------------------------------------------------------------------------\n",
    "\n",
    "feature = pd.concat([feature,pd.get_dummies(df[['categoryname','ipcategory_name','ipcategory_scope',\n",
    "                                                    'grandparent_category','weekday','dstipcategory_dominate',\n",
    "                                                    'srcipcategory_dominate']])], axis=1)\n",
    "\n",
    "\n",
    "feature.drop(['categoryname','ipcategory_name','ipcategory_scope',\n",
    "                                                    'grandparent_category','weekday','dstipcategory_dominate',\n",
    "                                                    'srcipcategory_dominate'],axis=1, inplace=True)\n",
    "\n",
    "#--------------------------Data Preprocessing------------------------------------------------------------\n",
    "X = feature\n",
    "y = df['notified']\n",
    "\n",
    "\n",
    "#__________________________________________________________________________________________________\n",
    "\n",
    "#Splitting into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "#X_test.fillna(X_train.mode(), inplace=True)\n",
    "\n",
    "# Feature Scaling---------------------------------------------------------------------------------------------\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "#----------------------------------------Decision Tree-----------------------------------------------\n",
    "DT_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "DT_model.fit(X_train,y_train)\n",
    "\n",
    "DT_yhat = DT_model.predict(X_test)\n",
    "DT_yhat_all = DT_model.predict(X)\n",
    "print(\"DT Jaccard index: %.2f\" % jaccard_similarity_score(y_test, DT_yhat))\n",
    "print(\"DT F1-score: %.2f\" % f1_score(y_test, DT_yhat, average='weighted') )\n",
    "\n",
    "#--------------------------\n",
    "pipeline = Pipeline([('transformer', sc), ('estimator', DT_model)])\n",
    "\n",
    "cv = KFold(n_splits=4)\n",
    "scores = cross_val_score(pipeline, X, y, cv = cv)\n",
    "print(scores)\n",
    "\n",
    "#----------------------------------SVM-----------------------------------------------------\n",
    "\n",
    "SVM_model = svm.SVC()\n",
    "SVM_model.fit(X_train, y_train) \n",
    "\n",
    "SVM_yhat = SVM_model.predict(X_test)\n",
    "print(\"SVM Jaccard index: %.2f\" % jaccard_similarity_score(y_test, SVM_yhat))\n",
    "print(\"SVM F1-score: %.2f\" % f1_score(y_test, SVM_yhat, average='weighted'))\n",
    "\n",
    "#-----------------------------------------------Logistic Regression----------------------------\n",
    "LR_model = LogisticRegression(C=0.01).fit(X_train,y_train)\n",
    "LR_yhat = LR_model.predict(X_test)\n",
    "LR_yhat_prob = LR_model.predict_proba(X_test)\n",
    "print(\"LR Jaccard index: %.2f\" % jaccard_similarity_score(y_test, LR_yhat))\n",
    "print(\"LR F1-score: %.2f\" % f1_score(y_test, LR_yhat, average='weighted') )\n",
    "print(\"LR LogLoss: %.2f\" % log_loss(y_test, LR_yhat_prob))\n",
    "\n",
    "# ---------------------------------------------KNN algorithm--------------------------------------------\n",
    "# Best k\n",
    "Ks=15\n",
    "mean_acc=np.zeros((Ks-1))\n",
    "std_acc=np.zeros((Ks-1))\n",
    "ConfustionMx=[];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    kNN_model = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    yhat = kNN_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mean_acc[n-1]=np.mean(yhat==y_test);\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "mean_acc\n",
    "\n",
    "k = 5\n",
    "#Train Model and Predict  \n",
    "kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "\n",
    "knn_yhat = kNN_model.predict(X_test)\n",
    "print(\"KNN Jaccard index: %.2f\" % jaccard_similarity_score(y_test, knn_yhat))\n",
    "print(\"KNN F1-score: %.2f\" % f1_score(y_test, knn_yhat, average='weighted'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------XGboost----------------------------------------\n",
    "#xgb_model = xgb.XGBClassifier() \n",
    "#xgb_model.fit(X_train, y_train) \n",
    "   \n",
    "# Predicting the Test set results \n",
    "#xgb_yhat = xgb_model.predict(X_test) \n",
    "#print(\"XGB Jaccard index: %.2f\" % jaccard_similarity_score(y_test, xgb_yhat))\n",
    "#print(\"XGB F1-score: %.2f\" % f1_score(y_test, xgb_yhat, average='weighted') )\n",
    "# Making the Confusion Matrix \n",
    "#from sklearn.metrics import confusion_matrix \n",
    "#cm = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "#----------------------------------Model Ealuation-------------------------------------------------------\n",
    "\n",
    "# initialize list of lists \n",
    "data = [['Decision Tree', jaccard_similarity_score(y_test, DT_yhat), f1_score(y_test, DT_yhat, average='weighted'),0],\n",
    "         ['SVM', jaccard_similarity_score(y_test, SVM_yhat), f1_score(y_test, SVM_yhat, average='weighted'),0],\n",
    "         ['Logistic Regression', jaccard_similarity_score(y_test, LR_yhat), f1_score(y_test, LR_yhat, average='weighted'),log_loss(y_test, LR_yhat_prob)],\n",
    "         ['KNN',jaccard_similarity_score(y_test, knn_yhat), f1_score(y_test, knn_yhat, average='weighted'),0]]\n",
    "         #['XGB',jaccard_similarity_score(y_test, xgb_yhat),f1_score(y_test, xgb_yhat, average='weighted') ]] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "scores = pd.DataFrame(data, columns = ['Algorithm','Jaccard-score', 'F1-score','LogLoss']) \n",
    "  \n",
    "# print dataframe. \n",
    "print(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
